---
title: "Assignment 03 - Solutions"
subtitle: "Statistical Computing and Empirical Methods"
author: "Qi Wu (2788491)"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

## A word of advice
Think of the SCEM labs as going to the gym: if you pay a gym membership, but instead of working out you use a machine to lift the weights for you, you won't get the benefits.

ChatGPT, DeepSeek, Claude and other GenAI tools can provide answers to most of the questions below. Before you try that, please consider the following: answering the specific questions below is not the point of this assignment. Instead, the questions are designed to give you the chance to develop a better understanding of estimation concepts and a certain level of _**statistical thinking**_. These are essential skills for any data scientist, even if they end up using generative AI - to write an effective prompt and to catch the common (often subtle) errors that AI produces when trying to solve anything non-trivial.

A very important part of this learning involves not having the answers ready-made for you, but instead taking the time to actually search for the answer, trying something, getting it wrong, and trying again.

So, make the best use of this session. The assignments are not marked, so it is much better to try the yourself even if you get incorrect answers (you'll be able to correct yourself later when you receive feedback) than to submit a perfect, but GPT'd solution.

-----

## IMPORTANT NOTES: 
- **DO NOT** change the code block names. Enter your solutions to each question into the predefined code blocks. 
- **DO NOT** add calls to `install.packages()` into your solutions. Some questions may require you to load packages using `library()`. Please do not use any other packages except the ones explicitly listed in the "setup" code block below. 

---

## Setup

This code block below sets up your session. The only think you should change in it is to replace `ABCDEF` by your student ID number, which will be used as the seed for your random number generators.

```{r setup, echo=FALSE}
## We will use your student ID as the seed for the random number generator.
MY_STUDENT_ID <- 2788491 # <-- Replace ABCDEF by your student ID number  
  

## These are the packages you can use (if needed) for the present assignment.
## If needed, you can run install.packages(tidyverse) in your machine, but 
## **do not** include any calls to install.packages() as part of your solution.
  
permitted.packages <- c("ggplot2", "dplyr", "tidyverse", "nycflights13") # <--- Don't change this

knitr::opts_chunk$set(echo = TRUE) # <---- Don't change this
```

## Part I: Point estimation of parameters

### Q1. Simulating data and estimating the mean

```{r Q1a}
## Question 1.a
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
xunif <- runif(12,min=50,max=80)
xunif.mean <- mean(x)
xunif.var  <- var(x)
print(xunif.mean)
print(xunif.var)
```

```{r Q1b}
## Question 1.b
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
xbern <- rbinom(1,200,0.25)
xbern.p <- mean(xbern)/200
xbern.p
print(paste("Population proportion of successes is less than that of sample proportion of successes:", xbern.p > 0.25))
```

------------------------------------------------------------------------

### Q2. Sampling distribution of the mean

```{r Q2a}
## Question 2.a
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
xbar.vector <- numeric(1000)

for (i in 1:1000) {
  sample <- rnorm(5, mean = 4,sd = 2)
  xbar.vector[i] <- mean(sample)
}

#plot histogram
library(ggplot2)
ggplot(data.frame(xbar = xbar.vector), aes(x = xbar)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black") +
  ggtitle( "Sampling Distribution of the Mean") +
  xlab("Sample Mean") +
  ylab("Frequency")
```

```{r Q2b}
## Question 2.b
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
xbar.mean <- mean(xbar.vector)
xbar.sd <- sd(xbar.vector)
sd_error <- 2/sqrt(5)
xbar.mean # less than 4
xbar.sd #less tha sd_error
sd_error 
```

------------------------------------------------------------------------

### Q3. Bias of an estimator

```{r Q3}
## Question 3
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
xvar.vector <- numeric(2000)

for (i in 1:2000) {
  sample <- rnorm(20, mean = 0,sd = 1)
  xvar.vector[i] <- sum((sample- mean(sample))^2)/20
}
bias <- mean(xvar.vector) - 1
bias #negative bias

```

------------------------------------------------------------------------

### Discussion: Maximum Likelihood Estimation (MLE)

Example of using the R function `optim()` to estimate the MLE values for the mean 
and variance of a normal distribution. _You don't need to change anything in the 
code block below._

```{r example}
## This is just an example

set.seed(1)
n    <- 100000 # sample size
mu   <- 12     # true mean
var  <- 9      # true variance


# Generate sample
x <- rnorm(n, mean = mu, sd = sqrt(var))

# log-likelihood for Normal(mu, sigma^2), given a sample X
# (Check lecture slides for the formula)
llik <- function(par, X) {
  mu     <- par[1]
  sigma2 <- par[2]
  n      <- length(X)
  if (sigma2 <= 0) return(Inf)  # variance must be positive
  llik <- -n * log(sqrt(2 * pi * sigma2)) - 0.5 * sum((X - mu)^2 / sigma2)
  return(llik)
}

# Initial guesses for mu and sigma^2 
# (any finite Real values of mu and of sigma2 > 0 should work)
init <- c(mu = 0, sigma2 = 1) 

# Run optimization
fit <- optim(par = init, fn = llik, X = x, 
             method = "L-BFGS-B",         # optimisation method to use
             lower = c(-Inf, 1e-9),       # Enforce positive variance (minimal allowed value: 10^-9)
             control = list(fnscale = -1) # To make it a maximisation problem
             )

fit$par
```

### Q4: Numerical computation of MLE value

```{r Q4a}
## Question 4.a
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
n    <- 10000 # sample size
theta  <- 5      # true value of parameter

# Generate sample
x <- rcauchy(n, location = theta, scale = 1)

# Cauchy log-likelihood function
cauchy_like <- function(theta, X) {
  n <- length(X)
  result <- -n * log(pi) - sum(log(1 + (X - theta)^2)) 
  return(result)
}
# Initial guesses for theta
init_theta <- c(theta = 3)

# Run optimization
fit_cauchy <- optim(par = init_theta, fn = cauchy_like, X = x, 
             method = "L-BFGS-B",         # optimisation method to use
             lower = -Inf,       # Enforce positive variance (minimal allowed value: 10^-9)
             upper = Inf,
             control = list(fnscale = -1) # To make it a maximisation problem
             )

fit_cauchy$par
```

```{r Q4b}
## Question 4.b
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
cauchy_solution <- function(n) {
  cauchy_paras <- numeric(n)
  for (i in 1:n) {
    x <- rcauchy(50, location = 8, scale = 1)
    cauchy_like <- function(theta, X) {
      n <- length(X)
      result <- -n * log(pi) - sum(log(1 + (X - theta)^2)) 
      return(result)
      }
    init_theta <- 3
    fit_cauchy <- optim(par = init_theta, fn = cauchy_like, X = x, 
             method = "L-BFGS-B",         # optimisation method to use
             lower = -Inf,# Enforce positive variance (minimal allowed value: 10^-9)
             upper = Inf,
             control = list(fnscale = -1) # To make it a maximisation problem
             )
    cauchy_paras[i] <- fit_cauchy$par
  }
  return(cauchy_paras)
}
cauchy.vector <- cauchy_solution(2000)
cauchy.vector
# plot density
ggplot(data.frame(theta_hat = cauchy.vector), aes(x = theta_hat)) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  ggtitle("Distribution of Cauchy MLE Estimates") +
  xlab("Estimated theta") +
  ylab("Density") +
  geom_vline(xintercept = 8, color = "red", linetype = "dashed") 
```

------------------------------------------------------------------------

## Part II: Data visualisation

### Q5: Basic plotting

```{r Q5a}
## Question 5.a
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
library(nycflights13)
head(flights)
delayed_flights_2h <- flights %>%
  filter(dep_delay < 120 & dep_delay >0) %>%
  slice_sample(prop = 0.1)
delayed_flights_2h

# plot histogram
ggplot(delayed_flights_2h,aes(x=delayed_flights_2h$dep_delay)) +
  geom_histogram(bins = 20, fill = "lightblue", color = "black") +
  ggtitle( "Departure Delay") +
  xlab("delay (minutes)") +
  ylab("Frequency")
  
```

```{r Q5b}
## Question 5.b
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
ggplot(delayed_flights_2h,aes(x=delayed_flights_2h$dep_delay)) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  ggtitle( "Departure Delay") +
  xlab("delay (minutes)") +
  ylab("Density")
  
```


```{r Q5c}
## Question 5.c
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
ggplot(data=delayed_flights_2h, aes(x=delayed_flights_2h$dep_delay, y=origin, fill=origin,alpha = 0.7))+
  geom_violin()+
  xlab("Departure Delay (minutes)")+
  ylab("Origin place")
```


```{r Q5d}
## Question 5.d
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
delays_EWR <- flights %>%
  filter(origin=="EWR")%>%
  slice_sample(prop = 0.1)
ggplot(data=delays_EWR, aes(y=delays_EWR$arr_delay, x=delays_EWR$dep_delay))+
  geom_point(na.rm = TRUE,color="red",alpha=0.5)+
  xlab("Departure Delay") + 
  ylab("Arrive Delay")
```


### Q6: Facetting and annotation


```{r Q6a}
## Question 6.a
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
ggplot(data=delayed_flights_2h, aes(y=delayed_flights_2h$arr_delay, x=delayed_flights_2h$dep_delay,colour = origin))+
  geom_point(alpha=0.3,na.rm = TRUE)+
  facet_wrap(~origin)+
  xlab("Departure Delay") + 
  ylab("Arrival Delay")+
  geom_smooth(method = "lm",se=FALSE,color="black",alpha=0.7)
```

```{r Q6b}
## Question 6.b
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
correlations <- flights %>%
  group_by(origin) %>%
  summarise(cor = cor(dep_delay, arr_delay, 
                      method = "spearman", 
                      use = "pairwise.complete.obs"))

correlations
```


```{r Q6c}
## Question 6.c
set.seed(MY_STUDENT_ID) # <--- Don't change this

# Your code here
##
annotation_data <- correlations %>%
  mutate(label = paste("corr =", round(cor, 3)),
         x = Inf, y = -Inf) 
ggplot(data=delayed_flights_2h, aes(y=delayed_flights_2h$arr_delay, x=delayed_flights_2h$dep_delay,colour = origin))+
  geom_point(alpha=0.3,na.rm = TRUE)+
  facet_wrap(~origin)+
  geom_text(data = annotation_data,aes(x=100,y=200,label=label),
            hjust=1,vjust=0,size=4,color="black")+
  xlab("Departure Delay") + 
  ylab("Arrival Delay")+
  geom_smooth(method = "lm",se=FALSE,color="black",alpha=0.7)
```